# -*- coding: utf-8 -*-
"""Timeseries_Energy_Forecasting_Final_Code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Oo8adCNNvxRMP2WJ0jeiAUEkWRXKlnkx
"""

# Importing all the necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

import random
import tensorflow as tf
import os

SEED = 42
np.random.seed(SEED)
random.seed(SEED)
tf.random.set_seed(SEED)
os.environ['PYTHONHASHSEED'] = str(SEED)

# Mounting the google drive
from google.colab import drive
drive.mount('/content/drive')

#Loading the Dataset
FILE_PATH = '/content/drive/MyDrive/Forecasting/household_power_consumption.txt'
df = pd.read_csv(
    FILE_PATH,
    sep=";",
    na_values="?",
    low_memory=False
)

print("Original shape:", df.shape)
df.info()

df.describe()

plt.figure(figsize=(12, 4))
df['Global_active_power'].plot()
plt.title("Global Active Power Consumption")
plt.xlabel("Time")
plt.ylabel("Global Active Power (kW)")
plt.grid()
plt.show()

plt.figure(figsize=(6,4))
plt.hist(df['Global_active_power'].dropna(), bins=50)
plt.title("Distribution of Global Active Power")
plt.xlabel("Global Active Power (kW)")
plt.ylabel("Frequency")
plt.grid()
plt.show()

# Handling date and time
df["Datetime"] = pd.to_datetime(
    df["Date"] + " " + df["Time"],
    format="%d/%m/%Y %H:%M:%S"
)

df.set_index("Datetime", inplace=True)
df.drop(["Date", "Time"], axis=1, inplace=True)
df.head()

# Converting to Numeric values & Handling the missing values
df = df.apply(pd.to_numeric)
df.fillna(method="ffill", inplace=True)
df.info()

#resampling the data minute data into hourly
df_hourly = df.resample('h').agg({
    'Global_active_power': 'mean',
    'Global_reactive_power': 'mean',
    'Voltage': 'mean',
    'Global_intensity': 'mean',
    'Sub_metering_1': 'sum',
    'Sub_metering_2': 'sum',
    'Sub_metering_3': 'sum'
})

print("Hourly shape:", df_hourly.shape)

# Log Transforming the Target data to Stabilize Peaks( This improved the result a bit than the previous)
df_hourly['Global_active_power'] = np.log1p(df_hourly['Global_active_power'])

# Time-based Feature Engineering
df_hourly['hour'] = df_hourly.index.hour
df_hourly['dayofweek'] = df_hourly.index.dayofweek
df_hourly['is_weekend'] = (df_hourly.index.dayofweek >= 5).astype(int)

df_hourly.head(10)

#selecting the features for the prediction.
features = [
    'Global_active_power',
    'Voltage',
    'Global_reactive_power',
    'Global_intensity',
    'Sub_metering_1',
    'Sub_metering_2',
    'Sub_metering_3',
    'hour',
    'dayofweek',
    'is_weekend'
]
# Converting the features into hourly sample.
data = df_hourly[features]

#some important plots of Exploratory Data Analysis (EDA)
# Hourly Global Active power Consumption
plt.figure(figsize=(10,4))
df_hourly['Global_active_power'].plot()
plt.title("Hourly Global Active Power Consumption")
plt.xlabel("Time")
plt.ylabel("kW")
plt.grid()
plt.show()

# Avg by Hour
df_hourly.groupby('hour')['Global_active_power'].mean().plot(kind='bar', figsize=(10,4))
plt.title("Average Energy Consumption by Hour")
plt.xlabel("Hour")
plt.ylabel("Avg kW")
plt.grid()
plt.show()

# Weekday vs Weekend
df_hourly.groupby('is_weekend')['Global_active_power'].mean().plot(kind='bar')
plt.xticks([0,1], ['Weekday','Weekend'], rotation=0)
plt.title("Weekday vs Weekend Energy Consumption")
plt.ylabel("Avg kW")
plt.grid()
plt.show()

# Monthly Consumption
df_hourly['month'] = df_hourly.index.month
df_hourly.groupby('month')['Global_active_power'].mean().plot(kind='bar', figsize=(10,4))
plt.title("Monthly Average Energy Consumption")
plt.xlabel("Month")
plt.ylabel("Avg kW")
plt.grid()
plt.show()

#Correlation Analysis
import seaborn as sns
import matplotlib.pyplot as plt
corr_matrix = df_hourly.corr()
plt.figure(figsize=(8, 6))
sns.heatmap(
    corr_matrix,
    annot=True,
    fmt=".2f",
    cmap="coolwarm",
    linewidths=0.5
)
plt.title("Feature Correlation Heatmap")
plt.show()

# Train / Validation / Test Split
total_len = len(data)

train_end = int(total_len * 0.70)
val_end   = int(total_len * 0.85)

train_data = data.iloc[:train_end]
val_data   = data.iloc[train_end:val_end]
test_data  = data.iloc[val_end:]

print("Train / Val / Test sizes:",
      len(train_data), len(val_data), len(test_data))

# Scaling the data.
scaler = MinMaxScaler()

train_scaled = scaler.fit_transform(train_data)
val_scaled   = scaler.transform(val_data)
test_scaled  = scaler.transform(test_data)

# 10. Sequence Creation (Multivariate)
def create_sequences(data, target_col_idx, window_size):
    X, y = [], []
    for i in range(window_size, len(data)):
        X.append(data[i-window_size:i, :])
        y.append(data[i, target_col_idx])
    return np.array(X), np.array(y)

#window size defined.
window_size = 48
target_col_idx = features.index('Global_active_power')

X_train, y_train = create_sequences(train_scaled, target_col_idx, window_size)
X_val,   y_val   = create_sequences(val_scaled,   target_col_idx, window_size)
X_test,  y_test  = create_sequences(test_scaled,  target_col_idx, window_size)

print("X_train:", X_train.shape, "y_train:", y_train.shape)
print("X_val  :", X_val.shape,   "y_val  :", y_val.shape)
print("X_test :", X_test.shape,  "y_test :", y_test.shape)

"""# **IMPLEMENTING THE LSTM MODEL**"""

from tensorflow.keras.layers import Dropout

#creating the lstm model
model = Sequential([
    LSTM(64, return_sequences=True, input_shape=(window_size, X_train.shape[2])),
    LSTM(32),
    Dense(1)
])
model.compile(
    optimizer='adam',
    loss='mse',
    metrics=['mae']
)

model.summary()

# Model Training
history = model.fit(
    X_train, y_train,
    epochs=25,
    batch_size=32,
    validation_data=(X_val, y_val),
    verbose=1
)

test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)

print("Test MSE (scaled):", test_loss)
print("Test MAE (scaled):", test_mae)

# LSTM Loss Curve
plt.plot(history.history['loss'], label='Train')
plt.plot(history.history['val_loss'], label='Validation')
plt.title("LSTM Training & Validation Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.grid()
plt.show()

y_pred_scaled = model.predict(X_test)

num_features = X_train.shape[2]

# Inverse Scaling
y_pred_log = scaler.inverse_transform(
    np.hstack([
        y_pred_scaled,
        np.zeros((y_pred_scaled.shape[0], num_features - 1))
    ])
)[:, 0]

y_test_log = scaler.inverse_transform(
    np.hstack([
        y_test.reshape(-1, 1),
        np.zeros((y_test.shape[0], num_features - 1))
    ])
)[:, 0]

y_pred_final = np.expm1(y_pred_log)
y_test_final = np.expm1(y_test_log)

#final results (RMSE and MAE scores)
rmse = np.sqrt(mean_squared_error(y_test_final, y_pred_final))
mae  = mean_absolute_error(y_test_final, y_pred_final)

print("FINAL TEST RMSE (kW):", rmse)
print("FINAL TEST MAE  (kW):", mae)

from sklearn.metrics import r2_score

r2 = r2_score(y_test_final, y_pred_final)

print("LSTM R² Score:", r2)

# Actual vs Predicted (LSTM)
plt.figure(figsize=(12,5))
plt.plot(y_test_final[:200], label="Actual")
plt.plot(y_pred_final[:200], label="Predicted")
plt.title("Actual vs Predicted Energy Consumption (LSTM)")
plt.legend()
plt.grid()
plt.show()

# Residual Error Plot (LSTM)
residuals = y_test_final - y_pred_final

plt.scatter(range(len(residuals)), residuals, alpha=0.4)
plt.axhline(0, color='red')
plt.title("LSTM Residual Error Plot")
plt.xlabel("Samples")
plt.ylabel("Residual (kW)")
plt.grid()
plt.show()

"""# **IMPLEMENTING THE GRU MODEL**"""

# GRU Model
from tensorflow.keras.layers import GRU
gru_model = Sequential([
    GRU(64, return_sequences=True, input_shape=(window_size, X_train.shape[2])),
    GRU(32),
    Dense(1)
])

gru_model.compile(
    optimizer='adam',
    loss='mse',
    metrics=['mae']
)

gru_model.summary()

#Trainning the GRU Model.
history_gru = gru_model.fit(
    X_train, y_train,
    epochs=25,
    batch_size=32,
    validation_data=(X_val, y_val),
    verbose=1
)

#result for the scaled data
test_loss_gru, test_mae_gru = gru_model.evaluate(X_test, y_test, verbose=0)
print("GRU Test MSE (scaled, log):", test_loss_gru)
print("GRU Test MAE (scaled, log):", test_mae_gru)

# GRU Training vs Validation Loss
plt.figure(figsize=(8,4))
plt.plot(history_gru.history['loss'], label='Train Loss')
plt.plot(history_gru.history['val_loss'], label='Validation Loss')
plt.title("GRU Training and Validation Loss Curve")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.grid(alpha=0.3)
plt.show()

# Inverse scaling the data and GRU Prediction
y_pred_gru_scaled = gru_model.predict(X_test)

y_pred_gru_log = scaler.inverse_transform(
    np.hstack([
        y_pred_gru_scaled,
        np.zeros((y_pred_gru_scaled.shape[0], num_features - 1))
    ])
)[:, 0]

# Reverse log transform
y_pred_gru_final = np.expm1(y_pred_gru_log)

#Final result for GRU MODEL(RMSE and GRU)
rmse_gru = np.sqrt(mean_squared_error(y_test_final, y_pred_gru_final))
mae_gru  = mean_absolute_error(y_test_final, y_pred_gru_final)

print("GRU FINAL RMSE (kW):", rmse_gru)
print("GRU FINAL MAE  (kW):", mae_gru)

r2_gru = r2_score(y_test_final, y_pred_gru_final)

print("GRU R² Score:", r2_gru)

# actual vs prediction graph
plt.figure(figsize=(12,5))
plt.plot(y_test_final[:200], label="Actual")
plt.plot(y_pred_gru_final[:200], label="GRU")
plt.title("Actual vs Predicted Energy Consumption (GRU)")
plt.legend()
plt.grid()
plt.show()

# actual vs prediction graph
plt.figure(figsize=(12,5))
plt.plot(y_test_final[:200], label="Actual")
plt.plot(y_pred_final[:200], label="LSTM")
plt.plot(y_pred_gru_final[:200], label="GRU")
plt.title("LSTM vs GRU Energy Consumption Forecasting")
plt.legend()
plt.grid()
plt.show()

# Residual Error Plot (GRU)
residuals_gru = y_test_final - y_pred_gru_final

plt.scatter(range(len(residuals_gru)), residuals_gru, alpha=0.4)
plt.axhline(0, color='red')
plt.title("GRU Residual Error Plot")
plt.xlabel("Samples")
plt.ylabel("Residual (kW)")
plt.grid()
plt.show()

results = pd.DataFrame({
    'Model': ['LSTM', 'GRU'],
    'RMSE (kW)': [rmse, rmse_gru],
    'MAE (kW)': [mae, mae_gru],
    'R² Score': [r2, r2_gru]
})

results







